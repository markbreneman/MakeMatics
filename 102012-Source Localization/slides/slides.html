<div class="slide-layout-title">
	<h1>Source localization in complex listening situations...</h1>
	<h4 style="display:inline">...<h4 style="color:red; display:inline">mark breneman's</h4> interpretation</h4>
		<!-- Extra notes -->
	<footer style="font-size: 15px;
float: right; margin-top: 12em;">
		<p class="slide-no-touch">Use <em>left/right arrows</em> to move between slides</p>
		<p class="slide-touch"><em>Swipe left or right</em> to move between slides</p>
	</footer>
</div>
<hr>

<div class="slide-layout-title">
	<h1>Whats this Paper All About?</h1>
	<h3>In the simplest terms this paper proposes a way to determine where sound is coming from</h3>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2>Well lets be honest for a moment this is super complicated.</h2>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2>In order to determine where sounds are coming from you have to;</h2>
	<ul>
	<li>Determine what sound your looking for</li>
	<li>Ignore other sounds</li>
	<li>Ignore reflections of sound</li>
	<li>Ignore superposition of sounds(effect of one sound on another)</li>
	</ul>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2>...And most importantly understand how sound is perceived physiologically.</h2>
	<p style="font-size:.75em">The authors of the paper point to this commonly accepted spatial model of hearing</p>
	<a href="media/image01.png"><img src= "media/image01.png" width="27%" style=" margin-left:35%"></a>
	<p style="font-size:.75em">...this makes it easy to understand...sort of</p>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2> Looking at the model the bottom three section(the ear parts) are all well understood physiologically</h2>
<a href="media/image01.png"><img src= "media/image01.png" width="27%" style=" margin-left:35%"></a>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2> Where this paper applies is at the binaural processing layer...where the sounds gets analyzed.</h2>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2> In order to understand how sound is analyzed two key terms are used</h2>
	<ul>
	<li><a href="http://en.wikipedia.org/wiki/Interaural_time_difference"> Interaural Time Difference (ITD)</a></li>
	<li>Interaural Level Difference (ILD)</li>
	</ul>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2> Interaural Time Difference (ITD) is the difference in arrival time of a sound between two ears</h2>
		<a href="http://www.ssc.education.ed.ac.uk/courses/deaf/dnov10i.html"><img src= "media/image02.jpg" width="27%" style=" margin-left:35%"></a>a
	<p style="font-size:.75em">With sound A it the ITD is equal where as with sound B there is a difference</p>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2> Interaural Level Difference (ILD) is the difference sound level(db) of a sound between two ears</h2>
	<a href="http://www.ssc.education.ed.ac.uk/courses/deaf/dnov10i.html"><img src= "media/image03.jpg" width="27%" style=" margin-left:35%"></a>
	<p style="font-size:.75em">The sound level in right ear will be less than that of left as the head will absorb some of the sound(high frequencies have greater difference)</p>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2>Using the concepts of ITD, and ITL the authors propose a <em style=" color:red;" >modeling mechanism</em> (a way of analyzing ITD's and ITLs) which can determine sound location in complex listening situations.</h2>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2>The modeling mechanism is uses a bunch of math....</h2>
	<img src= "media/image04.png" width="27%" >
	<img src= "media/image05.png" width="27%" >
	<img src= "media/image06.jpg" width="27%" >
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2>...but all that breaks down to the following</h2>
<h3> By considering only ITD and ILD cues occurring at time instants when they represent the direction of the of the selected sources and ignoring other cues, they can explain various aspects of source localization in complex listening situations. </h3>
</div>
<hr>


<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2>Okay but what does that mean?</h2>
	<p> Instead of paying attention to every "cue" or sound, the authors propose a filter of sorts called interaural coherence(IC).  IC is basically the maximum of the interaural cross-correlation function for values of lag within limits, e.g., +-1 or +-2 ms...this is basically the hearing response time of humans<a href= "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2906201/">(1/3 octave band)</a>.</p>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So hows it work?</h1>
	<h2> "By selecting ITD's and ILD cues which coincide with IC cues larger than a certain threshold, one can...obtain a set of ITS and ILD cues similar to corresponding cues of a source in free field( a sound in isolation or anechoic chamber)." parenthesis mine.</h2>
	</div>
<hr>

<div class="slide-layout-title">
	<h1>.....Okay I'll take your word for it.</h1>
	<hr>
	<h2>Thanks...</h2>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So whats the use of this "mechanism"?</h1>
	<h2>Well...</h2>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So whats the use of this "mechanism"?</h1>
	<h2>In most physical phenomena, an action correlates to sound, so this understanding could lead to a greater sensitivity, and understanding of what happens where.</h2>
</div>
<hr>

<div class="slide-layout-title">
	<h1>So whats the use of this "mechanism"?</h1>
	<h2>How about some "real" applications?</h2>
	<ul>
	<li> You could identify singers in a chorus who are off key and shame them...or praise those with perfect pitch</li>
	<li>Imagine being able to pinpoint in nature where a bird is at based off of their chirps(real life twitter)</li>
	<li>Knowing where sounds come from could allow audio engineers and artist the ability to create personalized sound experiences in environments.(tailored to the individual)</li>
	</ul>
</div>
<hr>


<div class="slide-layout-title">
	<h1>Cool so what the catch?</h1>
		<ul>
	<li>Well all this research doesn't consider any of the physiological influences of the ear (assumes perfect signal transmission)</li>
	<li>It relies on "critical" bands of sound...and honestly I'm not sure what critical is really based off of, but if a sound was outside of this critical band of frequencies the response might not identifiable.</li>
		<li>It also assumes that at some point there is a verifiable sound sample, without reflection, or superpositions.</li>
	</ul>
</div>
<hr>


<div class="slide-layout-title">
	<h1>Ok...So what are your thoughts on this paper?</h1>
	<p style="font-size:.75em">While this paper presents an interesting idea it does a terrible job of explaining it's application, and its internal workings. It seems to be focused purely towards acoustical engineers. I really wish they would have included more imagery, and more discussion on how the technology could be applied, as the idea and philosophy of identifying sounds location has a lot of great applications.</p>	
</div>
<hr>